{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONp3F9x6us5OUvLRrYvDYB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NerusuSahithi011/NLP/blob/main/lab_assignment08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CORPUS"
      ],
      "metadata": {
        "id": "gvyrVY9m8WNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=D1=\"Artificial Intelligence and Machine Learning Innovations\"\n",
        "D2=\"Cloud Computing and Modern Data Storage Solutions\"\n",
        "D3=\"Cybersecurity and Data Protection in the Digital Era\"\n",
        "D4=\"Blockchain Technology and Decentralized Systems\"\n",
        ""
      ],
      "metadata": {
        "id": "Ehnjmo6u_cXy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uni Gram Counts"
      ],
      "metadata": {
        "id": "yBeBcPkFCAks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Combine the text from D1, D2, D3, D4\n",
        "combined_text = f\"{D1} {D2} {D3} {D4}\"\n",
        "\n",
        "# Tokenize the combined text into words and convert to lowercase\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Calculate unigram counts\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "# Print the unigram counts\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "#Vocabulary size is length of unigrams\n",
        "V=len(unigram_counts)\n",
        "print(\"Vocabulary Size=\",V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qphBErXzB-pf",
        "outputId": "1f2fb355-13b5-4a51-9a44-35ce154fb064"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "and: 4\n",
            "data: 2\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            "machine: 1\n",
            "learning: 1\n",
            "innovations: 1\n",
            "cloud: 1\n",
            "computing: 1\n",
            "modern: 1\n",
            "storage: 1\n",
            "solutions: 1\n",
            "cybersecurity: 1\n",
            "protection: 1\n",
            "in: 1\n",
            "the: 1\n",
            "digital: 1\n",
            "era: 1\n",
            "blockchain: 1\n",
            "technology: 1\n",
            "decentralized: 1\n",
            "systems: 1\n",
            "Vocabulary Size= 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bi-Gram Counts"
      ],
      "metadata": {
        "id": "1-nrJFjLCJ53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1} {D2} {D3} {D4}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "# Print the bigram counts\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCNgkTOXCM02",
        "outputId": "de416710-ea3a-42e3-c304-87caa1fa6621"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "artificial intelligence: 1\n",
            "intelligence and: 1\n",
            "and machine: 1\n",
            "machine learning: 1\n",
            "learning innovations: 1\n",
            "innovations cloud: 1\n",
            "cloud computing: 1\n",
            "computing and: 1\n",
            "and modern: 1\n",
            "modern data: 1\n",
            "data storage: 1\n",
            "storage solutions: 1\n",
            "solutions cybersecurity: 1\n",
            "cybersecurity and: 1\n",
            "and data: 1\n",
            "data protection: 1\n",
            "protection in: 1\n",
            "in the: 1\n",
            "the digital: 1\n",
            "digital era: 1\n",
            "era blockchain: 1\n",
            "blockchain technology: 1\n",
            "technology and: 1\n",
            "and decentralized: 1\n",
            "decentralized systems: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tri-Gram Counts"
      ],
      "metadata": {
        "id": "pij9DU5DCSjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "combined_text = f\"{D1} {D2} {D3} {D4}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Generate bigrams\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "# Print the bigram counts\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThrYbGvtCSOq",
        "outputId": "6c465a01-659e-4815-9684-814c01951c91"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "artificial intelligence and: 1\n",
            "intelligence and machine: 1\n",
            "and machine learning: 1\n",
            "machine learning innovations: 1\n",
            "learning innovations cloud: 1\n",
            "innovations cloud computing: 1\n",
            "cloud computing and: 1\n",
            "computing and modern: 1\n",
            "and modern data: 1\n",
            "modern data storage: 1\n",
            "data storage solutions: 1\n",
            "storage solutions cybersecurity: 1\n",
            "solutions cybersecurity and: 1\n",
            "cybersecurity and data: 1\n",
            "and data protection: 1\n",
            "data protection in: 1\n",
            "protection in the: 1\n",
            "in the digital: 1\n",
            "the digital era: 1\n",
            "digital era blockchain: 1\n",
            "era blockchain technology: 1\n",
            "blockchain technology and: 1\n",
            "technology and decentralized: 1\n",
            "and decentralized systems: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts"
      ],
      "metadata": {
        "id": "_mUanjjgCdKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Artificial Intelligence\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"and Machine\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"Learning\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"Innovations\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV1PGWfcCeH5",
        "outputId": "d50ff56f-8845-43c8-ad74-e804e0345fd8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  and is  1.0\n",
            "Given sequence: 'Artificial Intelligence', predicted next word: 'and'\n",
            "probability of  learning is  1.0\n",
            "Given sequence: 'and Machine', predicted next word: 'learning'\n",
            "probability of  innovations is  1.0\n",
            "Given sequence: 'Learning', predicted next word: 'innovations'\n",
            "probability of  cloud is  1.0\n",
            "Given sequence: 'Innovations', predicted next word: 'cloud'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Bi-Gram Model"
      ],
      "metadata": {
        "id": "mBfbDd-dDuq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3mkLAHBDpEg",
        "outputId": "306c914e-9628-4889-bbcf-d3b578e45b66"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textand\n",
            "probability of  machine is  0.25\n",
            "probability of  modern is  0.25\n",
            "probability of  data is  0.25\n",
            "probability of  decentralized is  0.25\n",
            "Given sequence: 'and', predicted next word: 'machine'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts"
      ],
      "metadata": {
        "id": "L9ZCzc1vEILY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XTXGGz5EFoX",
        "outputId": "2b8360f2-8fb8-4a24-d40f-020e0f50548c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Tri-Gram Model\n"
      ],
      "metadata": {
        "id": "8RbcLTr6EQp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvp-7rktEQG5",
        "outputId": "f3c49933-a086-4bc8-f17d-5b997770163d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textArtificial Intelligence\n",
            "probability of  and is  1.0\n",
            "Given sequence: 'Artificial Intelligence', predicted next word: 'and'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening\n"
      ],
      "metadata": {
        "id": "C1yEh3LtE1xW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Cloud Computing\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"and  Mordern\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"Data storage\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \" for solutions \"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CII7xbikE24d",
        "outputId": "380a97d3-e364-4491-8627-60f1c4013ab7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of and is  0.08695652173913043\n",
            "Given sequence: 'Cloud Computing', predicted next word: 'and'\n",
            "Given sequence: 'and  Mordern', predicted next word: 'No bigram found starting with 'mordern'.'\n",
            "probability of solutions is  0.08695652173913043\n",
            "Given sequence: 'Data storage', predicted next word: 'solutions'\n",
            "probability of cybersecurity is  0.08695652173913043\n",
            "Given sequence: ' for solutions ', predicted next word: 'cybersecurity'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Laplace Smoothening based Bi-Gram Model"
      ],
      "metadata": {
        "id": "mNg7E38vF0rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbnn2RR4F0UN",
        "outputId": "fc14c350-4f32-4a55-8b9a-d394ee51458e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textData Storage\n",
            "probability of and is  0.08695652173913043\n",
            "Given sequence: 'Artificial Intelligence', predicted next word: 'and'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts based on laplace smoothening"
      ],
      "metadata": {
        "id": "DbFDvu2fF_k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Cybersecurity and data\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"prediction in the \"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_QqN9ucGAgw",
        "outputId": "8afc7152-2ad2-409e-cf7b-e3dcb79d0d4d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  protection is  0.08695652173913043\n",
            "Given sequence: 'Cybersecurity and data', predicted next word: 'protection'\n",
            "probability of  digital is  0.08695652173913043\n",
            "Given sequence: 'prediction in the ', predicted next word: 'digital'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Laplace Smoothening based Tri-Gram Model"
      ],
      "metadata": {
        "id": "-lX90gI8GcW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-19FhAmGdQl",
        "outputId": "b22a430d-92f3-479d-c960-0ce891c37376"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textprediction in the\n",
            "probability of  digital is  0.08695652173913043\n",
            "Given sequence: 'prediction in the', predicted next word: 'digital'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "YitNCcMmGn3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Cybersecurity and\"\n",
        "next_word1 = next_word_bigram_K(sequence1, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"data prediction\"\n",
        "next_word2 = next_word_bigram_K(sequence2, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"in the\"\n",
        "next_word3 = next_word_bigram_K(sequence3, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"digital era\"\n",
        "next_word4 = next_word_bigram_K(sequence4, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFX5RIjpG7CN",
        "outputId": "3095c2de-7f6b-4fd1-8654-78b9cb711e0d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of machine is  0.1\n",
            "probability of modern is  0.1\n",
            "probability of data is  0.1\n",
            "probability of decentralized is  0.1\n",
            "Given sequence: 'Cybersecurity and', predicted next word: 'machine'\n",
            "Given sequence: 'data prediction', predicted next word: 'No bigram found starting with 'prediction'.'\n",
            "probability of digital is  0.125\n",
            "Given sequence: 'in the', predicted next word: 'digital'\n",
            "probability of blockchain is  0.125\n",
            "Given sequence: 'digital era', predicted next word: 'blockchain'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Bi-Gram Model"
      ],
      "metadata": {
        "id": "GVvrRww6HZQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = next_word_bigram_K(ip_text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nal0yOCHaJK",
        "outputId": "032e5f12-b57b-4131-960f-c1a27126abea"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textin the\n",
            "probability of digital is  0.125\n",
            "Given sequence: 'in the', predicted next word: 'digital'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "T7h6hMvMHoMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}.'\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"Blackchain Technology is\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \" the decentralized systems\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVVs7D6LHnJv",
        "outputId": "f757b637-7bfa-42b4-e91b-98de83cf4334"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'Blackchain Technology is', predicted next word: 'No trigram found starting with 'technology is.''\n",
            "Given sequence: ' the decentralized systems', predicted next word: 'No trigram found starting with 'decentralized systems.''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Tri-Gram Model"
      ],
      "metadata": {
        "id": "ojLeNKK8IItH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CqAy7vuIJsa",
        "outputId": "818bef4c-d760-4c74-fd76-590d60c2006c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textcybersecurity and data\n",
            "probability of  protection is  0.125\n",
            "Given sequence: 'cybersecurity and data', predicted next word: 'protection'\n"
          ]
        }
      ]
    }
  ]
}