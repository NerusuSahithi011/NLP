{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxshC/+tnt50+bY3a7NnTJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NerusuSahithi011/NLP/blob/main/labassignment03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x58jvUDquaJs"
      },
      "outputs": [],
      "source": [
        "TASK 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab') # Added to download the missing resource\n",
        "sentence = \"Students are learning Natural Language Processing\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrNrwSVqumv7",
        "outputId": "c11622a4-412c-4048-c0e7-454940a7f133"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Students', 'NNS'), ('are', 'VBP'), ('learning', 'VBG'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Students are learning Natural Language Processing\")\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk8blFo9utnH",
        "outputId": "34238079-6110-4483-804b-a48e99c35a06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Students NOUN\n",
            "are AUX\n",
            "learning VERB\n",
            "Natural PROPN\n",
            "Language PROPN\n",
            "Processing NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying a startup in India.\")\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_, token.tag_)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr7cT5tbuxWp",
        "outputId": "5a96dd86-d315-4254-90ef-c49cc63cfa0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple PROPN NNP\n",
            "is AUX VBZ\n",
            "looking VERB VBG\n",
            "at ADP IN\n",
            "buying VERB VBG\n",
            "a DET DT\n",
            "startup NOUN NN\n",
            "in ADP IN\n",
            "India PROPN NNP\n",
            ". PUNCT .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"Loving the new AI features � #AI MachineLearning\"\n",
        "doc = nlp(text)\n",
        "nouns = []\n",
        "verbs = []\n",
        "for token in doc:\n",
        "  if token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
        "    nouns.append(token.text)\n",
        "  elif token.pos_ == \"VERB\":\n",
        "      verbs.append(token.text)\n",
        "noun_freq = Counter(nouns)\n",
        "verb_freq = Counter(verbs)\n",
        ""
      ],
      "metadata": {
        "id": "DzlxZ2HNu0xF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Noun Frequency:\", noun_freq)\n",
        "print(\"Verb Frequency:\", verb_freq)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYwDI2Kku4DL",
        "outputId": "d21210c3-58a9-42cf-a4a2-20f3fdd4b8af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noun Frequency: Counter({'AI': 2, '�': 1, 'MachineLearning': 1})\n",
            "Verb Frequency: Counter({'Loving': 1, 'features': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TASK 2"
      ],
      "metadata": {
        "id": "6u2b7yD1u9SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "sentence = \"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\"\n",
        "\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-KT6BavvA1g",
        "outputId": "ab0b4eb8-ec3a-4136-b612-d0b617944820"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('SR', 'NNP'), ('University', 'NNP'), ('campus', 'NN'), ('is', 'VBZ'), ('located', 'VBN'), ('in', 'IN'), ('Ananthasagar', 'NNP'), ('village', 'NN'), ('of', 'IN'), ('Hasanparthy', 'NNP'), ('Mandal', 'NNP'), ('in', 'IN'), ('Warangal', 'NNP'), (',', ','), ('Telangana', 'NNP'), (',', ','), ('India', 'NNP'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('in', 'IN'), ('150', 'CD'), ('acres', 'NNS'), (',', ','), ('with', 'IN'), ('both', 'DT'), ('separate', 'JJ'), ('hostel', 'NN'), ('facilities', 'NNS'), ('for', 'IN'), ('boys', 'NNS'), ('and', 'CC'), ('girls', 'NNS'), ('.', '.'), ('There', 'EX'), ('is', 'VBZ'), ('a', 'DT'), ('huge', 'JJ'), ('central', 'JJ'), ('library', 'NN'), ('along', 'IN'), ('with', 'IN'), ('Indias', 'NNP'), ('largest', 'JJS'), ('Technology', 'NN'), ('Business', 'NNP'), ('Incubator', 'NNP'), ('(', '('), ('TBI', 'NNP'), (')', ')'), ('in', 'IN'), ('tier', '$'), ('2', 'CD'), ('cities', 'NNS'), ('.', '.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\")\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCfjbrqGvDtQ",
        "outputId": "9261fdc2-0580-458a-9a76-58eecc6db38e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DET\n",
            "SR PROPN\n",
            "University PROPN\n",
            "campus NOUN\n",
            "is AUX\n",
            "located VERB\n",
            "in ADP\n",
            "Ananthasagar PROPN\n",
            "village NOUN\n",
            "of ADP\n",
            "Hasanparthy PROPN\n",
            "Mandal PROPN\n",
            "in ADP\n",
            "Warangal PROPN\n",
            ", PUNCT\n",
            "Telangana PROPN\n",
            ", PUNCT\n",
            "India PROPN\n",
            ". PUNCT\n",
            "\n",
            " SPACE\n",
            "It PRON\n",
            "is AUX\n",
            "in ADP\n",
            "150 NUM\n",
            "acres NOUN\n",
            ", PUNCT\n",
            "with ADP\n",
            "both DET\n",
            "separate ADJ\n",
            "hostel NOUN\n",
            "facilities NOUN\n",
            "for ADP\n",
            "boys NOUN\n",
            "and CCONJ\n",
            "girls NOUN\n",
            ". PUNCT\n",
            "\n",
            " SPACE\n",
            "There PRON\n",
            "is VERB\n",
            "a DET\n",
            "huge ADJ\n",
            "central ADJ\n",
            "library NOUN\n",
            "along ADP\n",
            "with ADP\n",
            "Indias PROPN\n",
            "largest ADJ\n",
            "Technology PROPN\n",
            "Business PROPN\n",
            "Incubator PROPN\n",
            "( PUNCT\n",
            "TBI PROPN\n",
            ") PUNCT\n",
            "in ADP\n",
            "tier NOUN\n",
            "2 NUM\n",
            "cities NOUN\n",
            ". PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\"\n",
        "     )\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_, token.tag_)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9S4klTovIPa",
        "outputId": "5fcfce5b-1441-4fda-f414-88e9ad197883"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DET DT\n",
            "SR PROPN NNP\n",
            "University PROPN NNP\n",
            "campus NOUN NN\n",
            "is AUX VBZ\n",
            "located VERB VBN\n",
            "in ADP IN\n",
            "Ananthasagar PROPN NNP\n",
            "village NOUN NN\n",
            "of ADP IN\n",
            "Hasanparthy PROPN NNP\n",
            "Mandal PROPN NNP\n",
            "in ADP IN\n",
            "Warangal PROPN NNP\n",
            ", PUNCT ,\n",
            "Telangana PROPN NNP\n",
            ", PUNCT ,\n",
            "India PROPN NNP\n",
            ". PUNCT .\n",
            "\n",
            " SPACE _SP\n",
            "It PRON PRP\n",
            "is AUX VBZ\n",
            "in ADP IN\n",
            "150 NUM CD\n",
            "acres NOUN NNS\n",
            ", PUNCT ,\n",
            "with ADP IN\n",
            "both DET DT\n",
            "separate ADJ JJ\n",
            "hostel NOUN NN\n",
            "facilities NOUN NNS\n",
            "for ADP IN\n",
            "boys NOUN NNS\n",
            "and CCONJ CC\n",
            "girls NOUN NNS\n",
            ". PUNCT .\n",
            "\n",
            " SPACE _SP\n",
            "There PRON EX\n",
            "is VERB VBZ\n",
            "a DET DT\n",
            "huge ADJ JJ\n",
            "central ADJ JJ\n",
            "library NOUN NN\n",
            "along ADP IN\n",
            "with ADP IN\n",
            "Indias PROPN NNP\n",
            "largest ADJ JJS\n",
            "Technology PROPN NNP\n",
            "Business PROPN NNP\n",
            "Incubator PROPN NNP\n",
            "( PUNCT -LRB-\n",
            "TBI PROPN NNP\n",
            ") PUNCT -RRB-\n",
            "in ADP IN\n",
            "tier NOUN NN\n",
            "2 NUM CD\n",
            "cities NOUN NNS\n",
            ". PUNCT .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"I LOVE NLP in SR University � #AI #MachineLearning\"\n",
        "doc = nlp(text)\n",
        "nouns = []\n",
        "verbs = []\n",
        "for token in doc:\n",
        "  if token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
        "    nouns.append(token.text)\n",
        "  elif token.pos_ == \"VERB\":\n",
        "    verbs.append(token.text)\n",
        "noun_freq = Counter(nouns)\n",
        "verb_freq = Counter(verbs)\n",
        ""
      ],
      "metadata": {
        "id": "MH6HGmKHvLwR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Noun Frequency:\", noun_freq)\n",
        "print(\"Verb Frequency:\", verb_freq)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz290tw0vPH4",
        "outputId": "af0e4256-79c2-4669-91d5-164eef721754"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noun Frequency: Counter({'NLP': 1, 'SR': 1, 'University': 1, '�': 1, 'AI': 1, 'MachineLearning': 1})\n",
            "Verb Frequency: Counter({'LOVE': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ASSIGNMENT - 3.3\n",
        "TASK 3\n",
        ""
      ],
      "metadata": {
        "id": "k1o28Ev8vSaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install nltk spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygI37RbzvTah",
        "outputId": "fbd574fa-b984-4690-8361-0e6ff4e10ea8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "IBGYbQ3Xvbyx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU8gm3slvhl8",
        "outputId": "89f2d6a2-7445-424a-f01f-ca6963248bee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        ""
      ],
      "metadata": {
        "id": "ksdcVfnivlWa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay_text = \"\"\"\n",
        "Academic writing plays a crucial role in the dissemination of knowledge.\n",
        "Researchers analyze data, construct arguments, and present findings in a\n",
        "structured manner. Effective academic writing enhances clarity and supports\n",
        "critical thinking across disciplines.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fallc9EBvob1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(essay_text)\n",
        "print(\"TOKENS:\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7VOugA1vrlY",
        "outputId": "fce7f380-921e-4010-faac-a95e8d5ca5cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOKENS:\n",
            "['Academic', 'writing', 'plays', 'a', 'crucial', 'role', 'in', 'the', 'dissemination', 'of', 'knowledge', '.', 'Researchers', 'analyze', 'data', ',', 'construct', 'arguments', ',', 'and', 'present', 'findings', 'in', 'a', 'structured', 'manner', '.', 'Effective', 'academic', 'writing', 'enhances', 'clarity', 'and', 'supports', 'critical', 'thinking', 'across', 'disciplines', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_pos_tags = nltk.pos_tag(tokens)\n",
        "print(\"\\nNLTK POS TAGS:\")\n",
        "print(nltk_pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvbHG_NWvtNr",
        "outputId": "a2dd3b1f-efc6-4118-e04b-fc344da901b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NLTK POS TAGS:\n",
            "[('Academic', 'NNP'), ('writing', 'NN'), ('plays', 'VBZ'), ('a', 'DT'), ('crucial', 'JJ'), ('role', 'NN'), ('in', 'IN'), ('the', 'DT'), ('dissemination', 'NN'), ('of', 'IN'), ('knowledge', 'NN'), ('.', '.'), ('Researchers', 'NNP'), ('analyze', 'JJ'), ('data', 'NNS'), (',', ','), ('construct', 'NN'), ('arguments', 'NNS'), (',', ','), ('and', 'CC'), ('present', 'JJ'), ('findings', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('structured', 'JJ'), ('manner', 'NN'), ('.', '.'), ('Effective', 'JJ'), ('academic', 'JJ'), ('writing', 'NN'), ('enhances', 'NNS'), ('clarity', 'NN'), ('and', 'CC'), ('supports', 'VBZ'), ('critical', 'JJ'), ('thinking', 'NN'), ('across', 'IN'), ('disciplines', 'NNS'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(essay_text)\n",
        "spacy_pos_tags = [(token.text, token.pos_) for token in doc]\n",
        ""
      ],
      "metadata": {
        "id": "u77YG0WHvzfw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nspaCy POS TAGS:\")\n",
        "print(spacy_pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z95dKm5Av1AZ",
        "outputId": "ce8643a6-bff7-4256-a02c-638943f98395"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "spaCy POS TAGS:\n",
            "[('\\n', 'SPACE'), ('Academic', 'ADJ'), ('writing', 'NOUN'), ('plays', 'VERB'), ('a', 'DET'), ('crucial', 'ADJ'), ('role', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('dissemination', 'NOUN'), ('of', 'ADP'), ('knowledge', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('Researchers', 'NOUN'), ('analyze', 'VERB'), ('data', 'NOUN'), (',', 'PUNCT'), ('construct', 'VERB'), ('arguments', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('present', 'ADJ'), ('findings', 'NOUN'), ('in', 'ADP'), ('a', 'DET'), ('\\n', 'SPACE'), ('structured', 'ADJ'), ('manner', 'NOUN'), ('.', 'PUNCT'), ('Effective', 'ADJ'), ('academic', 'ADJ'), ('writing', 'NOUN'), ('enhances', 'VERB'), ('clarity', 'NOUN'), ('and', 'CCONJ'), ('supports', 'NOUN'), ('\\n', 'SPACE'), ('critical', 'ADJ'), ('thinking', 'NOUN'), ('across', 'ADP'), ('disciplines', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_nouns = [word for word, tag in nltk_pos_tags if tag.startswith('NN')]\n",
        "nltk_noun_freq = Counter(nltk_nouns)\n",
        ""
      ],
      "metadata": {
        "id": "u_sU0_WRv5YD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nNLTK NOUNS (CONCEPTS):\")\n",
        "print(nltk_noun_freq)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGXllCzbv8b0",
        "outputId": "66525380-9ab7-46ed-d6fa-23d2a732cd44"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NLTK NOUNS (CONCEPTS):\n",
            "Counter({'writing': 2, 'Academic': 1, 'role': 1, 'dissemination': 1, 'knowledge': 1, 'Researchers': 1, 'data': 1, 'construct': 1, 'arguments': 1, 'findings': 1, 'manner': 1, 'enhances': 1, 'clarity': 1, 'thinking': 1, 'disciplines': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_nouns = [token.text for token in doc if token.pos_ == 'NOUN']\n",
        "spacy_noun_freq = Counter(spacy_nouns)\n"
      ],
      "metadata": {
        "id": "czTrx8JgwACi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nspaCy NOUNS (CONCEPTS):\")\n",
        "print(spacy_noun_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u76PUS51wCg-",
        "outputId": "b98d5f00-7dc8-40f2-d24b-b5bd1658285c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "spaCy NOUNS (CONCEPTS):\n",
            "Counter({'writing': 2, 'role': 1, 'dissemination': 1, 'knowledge': 1, 'Researchers': 1, 'data': 1, 'arguments': 1, 'findings': 1, 'manner': 1, 'clarity': 1, 'supports': 1, 'thinking': 1, 'disciplines': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_verbs = [word for word, tag in nltk_pos_tags if tag.startswith('VB')]\n",
        "nltk_verb_freq = Counter(nltk_verbs)"
      ],
      "metadata": {
        "id": "TrfbwnOYwFfa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nNLTK VERBS (ARGUMENTS):\")\n",
        "print(nltk_verb_freq)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSANKOSjwIhV",
        "outputId": "8a5c0dbb-9bfb-441a-adfe-e0f665d58579"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NLTK VERBS (ARGUMENTS):\n",
            "Counter({'plays': 1, 'supports': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_verbs = [token.text for token in doc if token.pos_ == 'VERB']\n",
        "spacy_verb_freq = Counter(spacy_verbs)\n"
      ],
      "metadata": {
        "id": "EClif6s5wMNm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nspaCy VERBS (ARGUMENTS):\")\n",
        "print(spacy_verb_freq)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-raQ-ArwPHL",
        "outputId": "b939836c-32ab-4598-d35f-c6373191d518"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "spaCy VERBS (ARGUMENTS):\n",
            "Counter({'plays': 1, 'analyze': 1, 'construct': 1, 'enhances': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMOST COMMON NOUNS (spaCy):\")\n",
        "print(spacy_noun_freq.most_common(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdNqti-uwS1R",
        "outputId": "1265e78b-e168-48db-a885-b4ac2f14938a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MOST COMMON NOUNS (spaCy):\n",
            "[('writing', 2), ('role', 1), ('dissemination', 1), ('knowledge', 1), ('Researchers', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMOST COMMON VERBS (spaCy):\")\n",
        "print(spacy_verb_freq.most_common(5))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KkLPcH4wVoS",
        "outputId": "abd41d5d-783e-47a6-f1ee-2b7b6638093c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MOST COMMON VERBS (spaCy):\n",
            "[('plays', 1), ('analyze', 1), ('construct', 1), ('enhances', 1)]\n"
          ]
        }
      ]
    }
  ]
}